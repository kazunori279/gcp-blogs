# Agentic Retrieval-Augmented Generation in Industry

## Overview: Agentic RAG vs. Standard RAG

**Retrieval-Augmented Generation (RAG)** refers to AI systems that combine a generative **large language model (LLM)** with an external knowledge source, so the model can retrieve up-to-date or domain-specific information to ground its responses[\[1\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=Retrieval%20augmented%20generation%20is%20an,tuning)[\[2\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=,the%20data%20to%20be%20retrieved). In a *standard RAG* pipeline, a user query is converted to a vector embedding and used to retrieve relevant documents (e.g. from a vector database), which are then provided to the LLM to generate a context-aware answer[\[2\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=,the%20data%20to%20be%20retrieved). This makes answers more accurate and prevents hallucinations by basing them on trusted data sources[\[3\]](https://www.domo.com/blog/what-is-agentic-rag-a-practical-guide-for-data-teams#:~:text=Traditional%20retrieval,reasoning%20to%20find%20an%20answer)[\[4\]](https://www.domo.com/blog/what-is-agentic-rag-a-practical-guide-for-data-teams#:~:text=1,based%20answer). However, traditional RAG follows a **static, one-shot workflow**: it simply fetches documents once and answers the query, which can be limiting for complex or multi-step tasks[\[5\]](https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/#:~:text=Agentic%20RAG%20is%20more%20dynamic,much%20better%20to%20changing%20situations)[\[6\]](https://www.domo.com/blog/what-is-agentic-rag-a-practical-guide-for-data-teams#:~:text=%2A%20Struggles%20with%20multi,%E2%80%8D).

**Agentic RAG** extends RAG by introducing autonomous *AI agents* into the loop[\[7\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=Agentic%20RAG%20is%20the%20use,and%20handle%20more%20complex%20workflows). An *agentic* RAG system uses an LLM-based agent that can **plan, reason, and use tools** in an iterative process, rather than just doing a single retrieval step[\[5\]](https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/#:~:text=Agentic%20RAG%20is%20more%20dynamic,much%20better%20to%20changing%20situations)[\[8\]](https://www.glean.com/blog/agentic-rag-explained#:~:text=Traditional%20RAG%20typically%20follows%20a,involves%20reasoning%20across%20multiple%20systems). The agent decides *when*, *where*, and *how* to retrieve information and can break a complex query into sub-tasks, call external tools or APIs, and refine its search based on intermediate results[\[9\]](https://www.glean.com/blog/agentic-rag-explained#:~:text=Agentic%20RAG%20introduces%20a%20more,Agents%20can)[\[10\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Specifically%2C%20the%20retrieval%20component%20becomes,different%20retriever%20tools%2C%20such%20as). In effect, the agent manages the retrieval-generation process dynamically: for example, it might retrieve from multiple databases and the web in sequence, ask follow-up questions, or verify retrieved facts before producing a final answer[\[11\]](https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/#:~:text=Agentic%20RAG%20is%20more%20dynamic,much%20better%20to%20changing%20situations)[\[9\]](https://www.glean.com/blog/agentic-rag-explained#:~:text=Agentic%20RAG%20introduces%20a%20more,Agents%20can). By adding this reasoning loop, **Agentic RAG is far more flexible and adaptive** than standard RAG. Key differences include:

* **Multi-Source Retrieval:** Traditional RAG typically connects an LLM to a single knowledge base, whereas agentic RAG can pull data from **multiple external sources** (multiple vector stores, web search, enterprise apps, etc.) in one session[\[12\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=,base%20containing%20proprietary%20organization%20data)[\[13\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Single). The agent can route queries to the appropriate source on the fly, so answers aren’t limited to one dataset.

* **Iterative Reasoning:** Instead of a fixed retrieve-then-answer sequence, an agentic system performs **multi-step reasoning and query refinement**. The AI agent can reformulate queries or try alternative tools if the initial results are insufficient[\[14\]](https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/#:~:text=Agentic%20RAG%20is%20more%20dynamic,much%20better%20to%20changing%20situations)[\[15\]](https://www.domo.com/blog/what-is-agentic-rag-a-practical-guide-for-data-teams#:~:text=%2A%20Adaptation%20and%20multi,They%20can%20interact). This adaptability lets it handle complex queries that require gathering and synthesizing information through several steps.

* **Tool Use and Actions:** Agentic RAG agents can invoke **external tools or APIs** (e.g. databases, calculators, web services) as part of the workflow[\[16\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Specifically%2C%20the%20retrieval%20component%20becomes,different%20retriever%20tools%2C%20such%20as). For instance, an agent might do a database lookup, call an internal API, or run a calculation in response to user instructions – capabilities beyond a standard RAG’s static document retrieval[\[17\]](https://www.domo.com/blog/what-is-agentic-rag-a-practical-guide-for-data-teams#:~:text=,the%20answers%20it%20can%20provide)[\[16\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Specifically%2C%20the%20retrieval%20component%20becomes,different%20retriever%20tools%2C%20such%20as).

* **Self-Optimization:** Because the agent “thinks” about how to answer, it can **validate and correct** its results. An agent can double-check retrieved context and iterate if something seems off, improving accuracy over a naive RAG that trusts the first retrieved snippet[\[18\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=,to%20optimize%20results%20over%20time)[\[9\]](https://www.glean.com/blog/agentic-rag-explained#:~:text=Agentic%20RAG%20introduces%20a%20more,Agents%20can). In contrast, a basic RAG system has no mechanism to self-correct or know if it retrieved the right data.

Overall, agentic RAG marries retrieval with the autonomy of agents. This means AI solutions that not only **find information** but also **take initiative in problem-solving**, adjusting their approach as needed. The trade-off is higher complexity and computational cost – coordinating multiple agent steps can be slower or use more tokens than a single retrieval – so agentic RAG is best applied when simple RAG is insufficient[\[19\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=Is%20agentic%20RAG%20better%20than,traditional%20RAG). When used appropriately, it yields more **adaptable and intelligent AI assistants** that are capable of tackling real-world tasks that require planning, tool integration, and on-the-fly learning[\[7\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=Agentic%20RAG%20is%20the%20use,and%20handle%20more%20complex%20workflows)[\[20\]](https://www.glean.com/blog/agentic-rag-explained#:~:text=,RAG%20provides%20smarter%2C%20more%20relevant).

## Industrial Use Cases for Agentic RAG

Many enterprises are beginning to deploy agentic RAG systems to solve practical business problems. Common use cases include:

* **Customer Support and Chatbots:** One prominent use of agentic RAG is in **customer service automation**. An AI support agent can retrieve answers from product manuals, FAQs, and customer data in real time, while also performing actions like ticket classification or form-filling. Unlike a basic FAQ bot, an agentic RAG chatbot can handle a multi-turn dialog: for example, it might ask the user for clarification, look up relevant policy documents, then draft a tailored solution. Businesses are using these agents to automatically resolve simpler inquiries with accurate, up-to-date answers, and then escalate complex cases to human staff[\[21\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=%2A%20Real,customers%20with%20current%2C%20accurate%20information). This reduces load on support teams by handling routine questions end-to-end. Agentic RAG-powered assistants ensure customers get **contextually relevant, detailed answers** drawn from the latest internal knowledge bases (and even external web info if needed) rather than generic responses.

* **Data and Document Analysis (Business Intelligence):** Organizations also apply agentic RAG to help analysts and managers make sense of large volumes of data. Here the AI agent acts as a **research and analytics assistant**. It can dynamically pull information from databases, data lakes, or reports, and even run computations or SQL queries via tools. For example, a business user could ask: *“Compare our Q4 sales by product, and identify any anomalies”*. An agentic system might retrieve sales figures from a data warehouse, run a calculation to find anomalies, then cross-reference with market data via an API – assembling the answer step by step. Importantly, the agent can combine **structured data queries and unstructured document retrieval** in one workflow. This is also invaluable for document-heavy tasks like compliance and legal analysis. Instead of manually reading through contracts or policies, an AI agent can fetch relevant sections from many documents and synthesize findings. One real-world scenario described in a recent analysis: an agentic RAG system could *“summarize a contract and flag anything that violates our procurement policy”* by using multiple specialized agents – one extracts key clauses from the contract, another retrieves the relevant internal policy text, and a third compares the two to highlight conflicts[\[22\]](https://www.glean.com/blog/agentic-rag-explained#:~:text=For%20example%2C%20if%20someone%20asks%2C,an%20agentic%20RAG%20system%20might). The result is then compiled into a summary report. Use cases like these show how agentic RAG can serve as a **knowledge worker assistant**, automating multi-step data gathering and analysis tasks that would be tedious for humans.

* **Code Assistants and Software Development:** Agentic RAG has also found a strong niche in developer tools and programming assistants. Code-focused LLMs (like GitHub Copilot Chat, Replit’s AI assistant, etc.) are increasingly **agentic** – they not only suggest code completions, but can perform retrieval and actions to help with development. For instance, a coding assistant agent can search a company’s internal codebase or documentation for relevant examples, fetch API references, or even run/test code in a sandbox. Replit recently *released an AI agent* that helps developers debug software – it can analyze error messages, look up documentation, and suggest fixes autonomously[\[23\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Enterprises%20are%20moving%20on%20from,and%20the%20possibilities%20are%20endless). Microsoft’s various *Copilot* products similarly use an agentic RAG approach: the AI “copilot” can pull information from documentation, knowledge bases, and user data, and incorporate it into its responses when helping with tasks in Office or assisting in coding[\[23\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Enterprises%20are%20moving%20on%20from,and%20the%20possibilities%20are%20endless). These code agents plan multiple steps (e.g. identify the problem, retrieve relevant code snippets/solutions, then apply them) without constant user prompts. By leveraging company-specific knowledge (like a private library’s docs or past ticket logs), an agentic RAG code assistant provides more **context-aware and actionable guidance** to engineers. This leads to faster debugging, on-demand technical answers, and even the ability to execute devops tasks – effectively acting as a junior developer that can research and carry out simple coding chores.

*(Beyond the above, other emerging use cases include AI agents for marketing and sales (e.g. drafting personalized content using both internal and external data), HR assistants (answering employee questions by querying policy manuals and HR systems), and operations automation (agents that monitor metrics and initiate workflows). In general, any scenario where an AI needs to consult* *multiple data sources or tools in real-time* *to complete a task is a good candidate for agentic RAG[\[24\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=Agentic%20RAG%20use%20cases)[\[25\]](https://www.glean.com/blog/agentic-rag-explained#:~:text=a%20static%20workflow%2C%20agentic%20RAG,and%20personalized%20internal%20search%20capabilities).)*

## Frameworks Enabling Agentic RAG

Implementing an agentic RAG system is complex, but a growing number of frameworks and libraries make it easier to build these intelligent pipelines. Popular frameworks and architectures include:

* **LangChain and LangGraph:** *LangChain* is an open-source framework that has become a standard toolkit for RAG and AI agent development. It provides abstractions to connect LLMs with data stores, APIs, and to define multi-step reasoning chains. LangChain introduced an orchestration component called **LangGraph**, which lets developers define agents as a graph of nodes (steps) and conditional edges[\[26\]](https://docs.langchain.com/oss/python/langgraph/agentic-rag#:~:text=Overview)[\[27\]](https://docs.langchain.com/oss/python/langgraph/agentic-rag#:~:text=In%20this%20tutorial%20we%20will,will%20have%20done%20the%20following). This graph-based approach gives granular control over an agent’s workflow – for example, you can create a retrieval agent that **decides whether or not to use the retriever tool** based on the query[\[27\]](https://docs.langchain.com/oss/python/langgraph/agentic-rag#:~:text=In%20this%20tutorial%20we%20will,will%20have%20done%20the%20following). With LangChain/LangGraph, one can configure routing logic, tool usage, memory, etc., in a flexible way. These tools essentially provide a framework to implement agentic RAG without reinventing the wheel, and they support integration with many vector databases, web search APIs, and other modules out of the box. (IBM’s guidance notes that frameworks like LangChain and LlamaIndex, along with LangGraph for orchestration, enable experimentation with agentic RAG architectures at minimal cost[\[28\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=web%20results).)

* **AutoGPT-Style Architectures (AutoGPT, BabyAGI, etc.):** In early 2023, open-source projects like **AutoGPT** and **BabyAGI** popularized the concept of “autonomous AI agents.” These systems are essentially looped agents that given a high-level goal will continuously generate tasks, retrieve information, and adjust plans until the goal is achieved. AutoGPT-style agents use an LLM (e.g. GPT-4) to plan actions, execute tool calls (such as web searches or code execution), then evaluate results and iterate. This architecture naturally lends itself to agentic RAG: an AutoGPT agent can include a *retrieval tool* to pull in external knowledge during its reasoning. In practice, many developers have extended AutoGPT or similar agents to incorporate RAG, so the agent can query vector databases or the internet when needed for facts. These architectures demonstrate what a fully *agentic* system can do – for example, browsing the web to collect information, synthesizing it, and generating a report with minimal human intervention. While AutoGPT itself is experimental, it has influenced many enterprise implementations. The core idea is giving the LLM agent a kind of **“control loop”** so it keeps working on a problem (using RAG and other tools) until it’s solved[\[23\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Enterprises%20are%20moving%20on%20from,and%20the%20possibilities%20are%20endless). Tech companies have even built on these ideas: for instance, Replit’s coding agent and Microsoft’s Copilots (mentioned earlier) are real-world products that embody AutoGPT-like planning combined with RAG retrieval[\[23\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Enterprises%20are%20moving%20on%20from,and%20the%20possibilities%20are%20endless).

* **LlamaIndex (GPT Index):** LlamaIndex is another open-source library focused on connecting LLMs with external data. It started as a toolkit for building RAG applications (indexing documents and enabling queries over them) and has evolved to support agentic behavior. One notable feature is its **Query Engine Tool**, which can serve as a modular retriever that an agent can call[\[29\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=,the%20leading%20frameworks%20for%20developing). Essentially, LlamaIndex lets you structure your data (documents, SQL, APIs) into indices and provides an interface for the LLM to query them intelligently. In an agentic RAG setup, LlamaIndex might be used to handle the retrieval side (with advanced features like query planning across multiple indices), while an agent orchestrator like LangChain handles the decision logic. This separation of concerns is useful in enterprise scenarios – for example, a company can use LlamaIndex to connect an LLM agent to both a vector store and a SQL database seamlessly. LlamaIndex, LangChain, and similar frameworks (e.g. **DSPy**, **Haystack**, or **Semantic Kernel** from Microsoft) all aim to simplify the creation of **tool-using AI agents**. They come with pre-built components for things like search, memory, and multi-step reasoning, which accelerates development of agentic RAG systems[\[30\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=,for%20tool%20use%20is%20sharing).

* **Multi-Agent Orchestration Frameworks:** Beyond single-agent systems, there are frameworks specifically designed to coordinate **multiple AI agents working together**. For example, **CrewAI** and OpenAI’s experimental **Swarm** framework allow multiple LLM agents to collaborate or compete on tasks[\[30\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=,for%20tool%20use%20is%20sharing). In an agentic RAG context, you might have specialized agents (one for each data source or one for each subtask) and a “manager” agent to delegate queries. Orchestration tools handle the messaging between agents and the merging of their results. This is an emerging area – for instance, projects like **AutoGen by Microsoft/Columbia** have showcased how a user’s query can be handled by a team of agents (one reasoning, one executing, etc.) in a RAG pipeline[\[31\]](https://lancedb.com/blog/agentic-rag-using-langgraph-building-a-simple-customer-support-autonomous-agent/#:~:text=What%E2%80%99s%20LangGraph%3F)[\[32\]](https://lancedb.com/blog/agentic-rag-using-langgraph-building-a-simple-customer-support-autonomous-agent/#:~:text=There%20are%20many%20tools%20available,with%20the%20following%20internal%20components). Such setups can solve complex workflows (e.g. an “analyst” agent asks a “database” agent for data, then a “report-writer” agent compiles the answer). While multi-agent systems add overhead, they mirror real-world teams and can bring **specialization** (each agent is expert at its own tool/domain) and **verification** (agents cross-check each other) to increase robustness[\[33\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=Meanwhile%2C%20agentic%20RAG%20is%20a,and%20check%20each%20other%E2%80%99s%20work)[\[34\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=The%20benefit%20of%20agentic%20RAG,more%20robust%20and%20accurate%20responses). Notably, enterprise platforms like IBM’s **watsonx Orchestrate** are also providing UIs and services to design these multi-agent RAG workflows for business process automation[\[35\]](https://www.ibm.com/case-studies/comparus-gmbh#:~:text=The%20next%20step%20is%20to,involved%20and%20the%20data%20repositories)[\[36\]](https://www.ibm.com/case-studies/comparus-gmbh#:~:text=integration%20of%20services%20and%20back,involved%20and%20the%20data%20repositories).

## Examples of Agentic RAG in Practice

To illustrate how agentic RAG is implemented, here are a few concrete examples and case studies:

* **Autonomous Document Processing:** A large consulting firm implemented an AI assistant to streamline contract review. Using an agentic RAG approach, the assistant can accept a lengthy contract and a query like *“Find any clauses that conflict with our company’s policies and summarize the issues.”* Behind the scenes, the system employs multiple agents working together (as described earlier). One agent retrieves relevant company policies from an internal wiki, another reads the contract text to extract key obligations and terms, and a third agent compares the two sets of information. Finally, the system’s LLM generates a summary report highlighting the conflicts and recommended changes. This multi-agent RAG workflow effectively automates a task that normally requires a legal team’s careful reading. It showcases the power of agentic RAG for **knowledge-intensive tasks** – the agents can ingest huge volumes of text, dynamically navigate different data sources, and produce a consolidated output. (This example is analogous to scenarios discussed by Glean and others, where RAG agents collaborate to analyze documents[\[22\]](https://www.glean.com/blog/agentic-rag-explained#:~:text=For%20example%2C%20if%20someone%20asks%2C,an%20agentic%20RAG%20system%20might).) Such an AI assistant saves time in compliance, due diligence, and other document-heavy processes while ensuring the analysis is backed by all relevant data.

* **Developer Coding Assistant (Replit’s Ghostwriter):** Replit, an online coding platform, has deployed an AI agent called Ghostwriter that helps users write and debug code. This agentic system is not limited to just suggesting code based on context (as a vanilla code autocomplete might). It can actually perform **goal-directed actions**: for instance, a user can ask, *“Why is my Python function returning an error?”* and the Ghostwriter agent will inspect the code, recognize the error type, perhaps retrieve documentation on that error or search Replit’s knowledge base for similar issues, and then suggest a fix. Replit’s agent uses the ReAct paradigm (Reason+Act) to plan a sequence of steps. According to reports, they have an agent that can “help developers build and debug software” autonomously[\[23\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Enterprises%20are%20moving%20on%20from,and%20the%20possibilities%20are%20endless). In practice, Ghostwriter may run the code in a sandbox (tool use), observe the traceback (perception), retrieve an explanation of the error, and then formulate a corrected code snippet. This is a prime example of an *agentic RAG in production*: it integrates a code execution tool, documentation retrieval, and an LLM that reasons about the problem. The outcome is a much more interactive and **intelligent coding assistant** that improves developer productivity (it doesn’t just complete code, but understands and resolves issues).

* **Enterprise Copilots (Microsoft 365 Copilot):** Microsoft has introduced “Copilot” AI features across Office 365 and other products, which function as agentic RAG systems for general knowledge work. For example, **Microsoft 365 Copilot** can draft an email or generate a meeting summary by pulling information from your organization’s files, emails, and Teams chats. Internally, it uses an agent that calls the Microsoft Graph API (to retrieve data from your files/calendar/etc.), possibly performs web searches (Bing) if needed, and then composes a response using an LLM. This approach was hinted at when Microsoft announced new copilots that *“work alongside users to provide suggestions in completing tasks”* across apps[\[23\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Enterprises%20are%20moving%20on%20from,and%20the%20possibilities%20are%20endless). Another instance is **GitHub Copilot Chat**, which not only suggests code but can answer questions about your project by retrieving relevant code from the repository or documentation. These copilots demonstrate agentic RAG by **selecting from multiple data sources** (documents, emails, code repos) and by executing specialized tools (e.g. a scheduler or a web search) depending on the user’s request. The result is a versatile AI assistant that behaves almost like a knowledgeable coworker who knows where to find answers. Early user stories indicate that such systems significantly reduce the time spent searching for information across different apps – the AI will gather context from wherever it resides and present an integrated answer. This is made possible by the agent’s ability to reason about *which* data source or function to leverage for a given query, a hallmark of agentic RAG.

* **Customer Service Agent at an E-commerce Company:** As a final example, consider a retail company that implemented an **AI customer support agent** to handle inquiries on its website. This agent is given access to the company’s knowledge base articles, order database, and an FAQ API. When a customer asks a question like *“I haven’t received my order – what should I do?”*, the agent goes through several steps: (1) It parses the query and identifies it needs order status information. (2) It calls an order-tracking API (via a tool) to check the status of the customer’s order. (3) It retrieves any relevant return/refund policy from the knowledge base (using vector search on policy docs). (4) It then generates a response that explains the order status (e.g. *“your package is in transit and will arrive tomorrow”*) and advises on next steps per the policy (e.g. *“if it doesn’t arrive by Friday, you can apply for a refund using this link…”*). All of this happens in one seamless interaction with the user. Traditional RAG alone might only fetch a canned answer about shipping delays, but the **agentic** approach allows real-time integration of customer-specific data and company policies. IBM notes that agentic RAG is ideal for such scenarios requiring multiple data queries – the agent can tap into databases and knowledge repositories together to give accurate, personalized answers[\[37\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=While%20agentic%20RAG%20can%20suit,Agentic%20RAG%20applications%20include)[\[21\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=%2A%20Real,customers%20with%20current%2C%20accurate%20information). In production, companies have reported that automating these workflows can cut down support costs and improve response times dramatically, while still providing trustworthy answers grounded in the latest data.

These examples show a spectrum of agentic RAG applications: from behind-the-scenes process automation (document analysis) to end-user-facing assistants (coding copilots, chatbots). In each case, the AI agent actively **orchestrates retrieval and actions** to meet the user’s request, rather than responding with a pre-scripted solution. Many organizations are piloting such systems, and early success stories (Replit, Microsoft, etc.) suggest that agentic RAG can unlock significant efficiency and capability gains in enterprise settings[\[23\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Enterprises%20are%20moving%20on%20from,and%20the%20possibilities%20are%20endless)[\[38\]](https://www.ibm.com/case-studies/comparus-gmbh#:~:text=50,in%20queries%20to%20the%20bank).

![][image1]  
*An example of a multi-agent RAG architecture: a central AI agent (LLM) coordinates several specialized* *retrieval agents, each connected to different tools or data sources (vector databases, web search, Slack, email, etc.). This design enables the system to query heterogeneous information sources and aggregate results intelligently[\[39\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=For%20example%2C%20you%20can%20have,public%20information%20from%20web%20searches)[\[16\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Specifically%2C%20the%20retrieval%20component%20becomes,different%20retriever%20tools%2C%20such%20as). By distributing sub-tasks among multiple agents, the overall agentic RAG system can solve complex queries that no single database or static workflow could handle.*

## Tools and Ecosystem Components in Agentic RAG Deployments

Building agentic RAG solutions involves assembling a variety of tools and infrastructure components. The typical ecosystem includes:

* **Vector Databases for Knowledge Storage:** Vector databases (or indexes) are a core component of most RAG systems. They store high-dimensional embeddings of texts and allow similarity search to find relevant documents for a query. Popular choices include **Pinecone**, **Weaviate**, **Qdrant**, **Chroma**, and **LanceDB**, among others. These databases are optimized for fast semantic search at scale. In agentic RAG, a single agent may interface with multiple vector stores (each holding different content, e.g. one for product docs and one for legal docs). The performance and precision of vector search is crucial – it ensures the agent has the right information to work with. For instance, Qdrant’s solution notes that using a vector DB as the “backbone” provides *“fast, scalable semantic search that excels at retrieving precise information – even from massive datasets.”*[\[40\]](https://qdrant.tech/documentation/agentic-rag-langgraph/#:~:text=how%20to%20build%20an%20Agentic,search%20into%20one%20seamless%20workflow) Without a good vector store, the agent’s retrieval tool would be slow or might return irrelevant context. Many enterprise RAG deployments leverage vector DB services to index proprietary data (text documents, transcripts, knowledge base articles, etc.), enabling the AI agent to query that data in realtime.

* **Embedding Models and Retrievers:** Along with vector stores, one needs embedding models (to convert queries and documents into vectors) and **retriever logic** to handle searches. These are often packaged together. Solutions like **OpenAI’s text-embedding-ada** or **Sentence Transformers** provide the embeddings, while retriever libraries handle the search and ranking. In agentic RAG, retrievers can be more sophisticated: an agent might use **hybrid retrievers** (combining keyword search and vector similarity) or chain multiple retrievals. There are also tool-specific retrievers – for example, an agent might call a *web search API* (like Brave Search or Bing) as a retriever for external information[\[41\]](https://qdrant.tech/documentation/agentic-rag-langgraph/#:~:text=For%20web%20search%2C%20we%20create,effective%20tool%20using%20Brave%20Search)[\[42\]](https://qdrant.tech/documentation/agentic-rag-langgraph/#:~:text=The%20search_tool%20function%20leverages%20the,key%2C%20and%20returns%20the%20results). Another retriever could query an internal SQL database for structured data. So the retriever category in agentic RAG is broad: it encompasses any mechanism to fetch information. Often an agent will have a **tool belt** with several retriever tools (one for each type of source). This requires orchestration but greatly expands the knowledge accessible to the AI. For instance, an agent might first use a vector store retriever on a private corpus, and if that yields insufficient info, then use a web search retriever – all within one session. Ensuring each retriever is properly configured (with quality embeddings, up-to-date indexes, etc.) is a key engineering task in these deployments.

* **LLM Models (Generative AI):** At the heart of agentic RAG is the generative AI model (or models) that drive the agent’s reasoning and response generation. Many systems use large pretrained LLMs (like GPT-4, Claude, or Llama 2\) with prompt engineering to imbue them with agent behavior. The LLM needs to support **function calling or tool use** interfaces – for example, OpenAI’s function calling API allows the model to output a structured tool invocation which the system can execute[\[43\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Language%20models%20are%20the%20main,this%20feature%20to%20their%20clients)[\[44\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=In%20June%202023%2C%20OpenAI%20released,executors%2C%20databases%2C%20calculators%2C%20and%20more). Newer open-source models and APIs (like Cohere, Anthropic, etc.) also allow calling tools or plugins[\[44\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=In%20June%202023%2C%20OpenAI%20released,executors%2C%20databases%2C%20calculators%2C%20and%20more). This feature is essential for agentic RAG because it’s how the agent decides to retrieve or take an action mid-generation. Companies typically choose an LLM based on a trade-off of capability, cost, and privacy. Some use powerful proprietary models (GPT-4) for best results, while others opt for fine-tuned open-source models they can run in-house (to control data and costs). There is also a trend toward **specialized models** for different agents: e.g. a smaller, faster model might handle straightforward queries and route only complex ones to a more powerful model. In any case, the LLM’s quality directly impacts the agent’s reasoning quality. Ensuring the model has been instructed on how to behave agentically (via system prompts that encourage step-by-step thinking and tool use) is part of the implementation. Many frameworks come with default prompts/templates to help the LLM act as an agent out of the box[\[45\]](https://huggingface.co/learn/cookbook/en/agent_rag#:~:text=Since%20we%20initialized%20the%20agent,with%20your%20own%20as%20needed)[\[46\]](https://huggingface.co/learn/cookbook/en/agent_rag#:~:text=%3E%3E%3E%20agent_output%20%3D%20agent.run%28,a%20model%20to%20the%20Hub).

* **Orchestration and Memory Tools:** Orchestration components coordinate the data flow between the user, the LLM, and tools. Frameworks like LangChain, LlamaIndex, **IBM watsonx Orchestrate**, and others provide this orchestration layer[\[28\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=web%20results)[\[35\]](https://www.ibm.com/case-studies/comparus-gmbh#:~:text=The%20next%20step%20is%20to,involved%20and%20the%20data%20repositories). They manage the sequence: user query \-\> agent reasoning \-\> tool calls \-\> intermediate results \-\> final answer. In an agentic RAG deployment, the orchestration tool is what allows integration of multiple tools and multi-turn interactions. These frameworks often include **memory** utilities as well – enabling the agent to store and recall information during a session. For example, an agent might cache what it has already looked up (semantic caching of previous queries and results) so it doesn’t repeat work[\[47\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=tasks,LLMs%20with%20three%20significant%20characteristics)[\[48\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=,of%20queries%2C%20context%20and%20results). Memory can be short-term (within one conversation) or long-term (persisted across sessions to make the agent learn over time). Effective use of memory helps the agent build context, especially in enterprise applications where a user might ask follow-up questions or where an investigation spans multiple queries. Orchestration tools also handle things like **error recovery** – if an agent gets stuck or a tool fails, there are often guardrails or human-in-the-loop triggers to intervene. In sum, this layer is the “glue” that binds the LLM and tools into a coherent agentic system. Companies leveraging agentic RAG will either use a ready framework or develop a custom orchestrator to suit their architecture.

* **External Connectors and Plugins:** A rich ecosystem of connectors allows agentic RAG systems to interface with real-world data and services. These include APIs for enterprise applications (CRM systems, ticketing systems, databases), plugins for web services, and custom tools for proprietary systems. For example, an e-commerce company’s agent might have a plugin to query the order management system; a financial analyst’s agent might have a connector to a live stock prices API. Agentic RAG thrives on such integrations because they extend the agent’s capabilities beyond text. Many LLM platforms now support a plugin architecture – OpenAI has plugins for things like web browsing, Slack, Zapier, etc., and open-source communities are building similar **tool libraries**. In practice, an agent developer will select a set of tools that align with the use case (e.g. a *calculator* tool for math, a *search* tool for external info, a *database* tool for internal data). These tools must be described to the LLM (so it knows when and how to use them). During deployment, maintaining these connectors (API keys, access control, data refresh schedules for indices) becomes an operational task. Security and permissioning are especially important: the system should ensure the agent only accesses data it’s allowed to, and that confidential data retrieved doesn’t leak into responses improperly. Therefore, robust **governance** (monitoring the agent’s actions, having audit logs of tool usage, rate limiting, etc.) is another component of enterprise agentic RAG solutions[\[49\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Limitations%20of%20Agentic%20RAG). Leading companies emphasize sandboxing the agent’s actions to prevent unwanted outcomes while still empowering it to be useful.

In summary, deploying an agentic RAG system requires a **stack** that spans *knowledge storage*, *model inference*, and *tool execution*. By combining these components – a powerful LLM agent, high-quality retrievers and vector stores, orchestration logic, and a suite of domain-specific tools – organizations can create AI agents that are **knowledgeable, action-oriented, and context-aware**. This ecosystem is rapidly maturing: vendors are offering integrated solutions (for example, NVIDIA’s NeMo toolkit provides retriever \+ agent infrastructure[\[50\]](https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/#:~:text=,agents%20and%20AI%20query%20engines), and cloud platforms are adding vector DB and prompt orchestration services), and open-source options abound. As a result, enterprises now have the building blocks to bring agentic RAG from concept to production, unlocking AI systems that **“actively reason about, evaluate, and optimize the retrieval process”**[\[51\]](https://www.matillion.com/learn/blog/agentic-rag#:~:text=What%20is%20Agentic%20RAG%3F%20How,the%20entire%20information%20retrieval%20process) to deliver far more dynamic and useful outcomes than earlier generations of AI assistants.

**Sources:** The information in this report is drawn from recent industry literature and case studies on agentic RAG, including IBM’s overview of Agentic RAG[\[7\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=Agentic%20RAG%20is%20the%20use,and%20handle%20more%20complex%20workflows)[\[12\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=,base%20containing%20proprietary%20organization%20data), Nvidia’s technical blog on dynamic knowledge for AI agents[\[5\]](https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/#:~:text=Agentic%20RAG%20is%20more%20dynamic,much%20better%20to%20changing%20situations), enterprise AI blogs (e.g. Glean[\[8\]](https://www.glean.com/blog/agentic-rag-explained#:~:text=Traditional%20RAG%20typically%20follows%20a,involves%20reasoning%20across%20multiple%20systems)[\[9\]](https://www.glean.com/blog/agentic-rag-explained#:~:text=Agentic%20RAG%20introduces%20a%20more,Agents%20can) and Weaviate[\[16\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Specifically%2C%20the%20retrieval%20component%20becomes,different%20retriever%20tools%2C%20such%20as)) describing the benefits of agentic approaches, and real-world examples such as Replit’s and Microsoft’s AI agent deployments[\[23\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Enterprises%20are%20moving%20on%20from,and%20the%20possibilities%20are%20endless). These sources and examples collectively highlight how agentic RAG is being used to **boost accuracy, adaptability, and autonomy** of AI systems in practical business contexts. Each reference is provided inline to indicate the source of specific insights and claims.

---

[\[1\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=Retrieval%20augmented%20generation%20is%20an,tuning) [\[2\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=,the%20data%20to%20be%20retrieved) [\[7\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=Agentic%20RAG%20is%20the%20use,and%20handle%20more%20complex%20workflows) [\[12\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=,base%20containing%20proprietary%20organization%20data) [\[18\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=,to%20optimize%20results%20over%20time) [\[19\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=Is%20agentic%20RAG%20better%20than,traditional%20RAG) [\[21\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=%2A%20Real,customers%20with%20current%2C%20accurate%20information) [\[24\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=Agentic%20RAG%20use%20cases) [\[28\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=web%20results) [\[33\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=Meanwhile%2C%20agentic%20RAG%20is%20a,and%20check%20each%20other%E2%80%99s%20work) [\[37\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=While%20agentic%20RAG%20can%20suit,Agentic%20RAG%20applications%20include) [\[47\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=tasks,LLMs%20with%20three%20significant%20characteristics) [\[48\]](https://www.ibm.com/think/topics/agentic-rag#:~:text=,of%20queries%2C%20context%20and%20results) What is Agentic RAG? | IBM

[https://www.ibm.com/think/topics/agentic-rag](https://www.ibm.com/think/topics/agentic-rag)

[\[3\]](https://www.domo.com/blog/what-is-agentic-rag-a-practical-guide-for-data-teams#:~:text=Traditional%20retrieval,reasoning%20to%20find%20an%20answer) [\[4\]](https://www.domo.com/blog/what-is-agentic-rag-a-practical-guide-for-data-teams#:~:text=1,based%20answer) [\[6\]](https://www.domo.com/blog/what-is-agentic-rag-a-practical-guide-for-data-teams#:~:text=%2A%20Struggles%20with%20multi,%E2%80%8D) [\[15\]](https://www.domo.com/blog/what-is-agentic-rag-a-practical-guide-for-data-teams#:~:text=%2A%20Adaptation%20and%20multi,They%20can%20interact) [\[17\]](https://www.domo.com/blog/what-is-agentic-rag-a-practical-guide-for-data-teams#:~:text=,the%20answers%20it%20can%20provide) What is Agentic RAG? A Practical Guide for Data Teams | Domo

[https://www.domo.com/blog/what-is-agentic-rag-a-practical-guide-for-data-teams](https://www.domo.com/blog/what-is-agentic-rag-a-practical-guide-for-data-teams)

[\[5\]](https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/#:~:text=Agentic%20RAG%20is%20more%20dynamic,much%20better%20to%20changing%20situations) [\[11\]](https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/#:~:text=Agentic%20RAG%20is%20more%20dynamic,much%20better%20to%20changing%20situations) [\[14\]](https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/#:~:text=Agentic%20RAG%20is%20more%20dynamic,much%20better%20to%20changing%20situations) [\[50\]](https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/#:~:text=,agents%20and%20AI%20query%20engines) Traditional RAG vs. Agentic RAG—Why AI Agents Need Dynamic Knowledge to Get Smarter | NVIDIA Technical Blog

[https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/](https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/)

[\[8\]](https://www.glean.com/blog/agentic-rag-explained#:~:text=Traditional%20RAG%20typically%20follows%20a,involves%20reasoning%20across%20multiple%20systems) [\[9\]](https://www.glean.com/blog/agentic-rag-explained#:~:text=Agentic%20RAG%20introduces%20a%20more,Agents%20can) [\[20\]](https://www.glean.com/blog/agentic-rag-explained#:~:text=,RAG%20provides%20smarter%2C%20more%20relevant) [\[22\]](https://www.glean.com/blog/agentic-rag-explained#:~:text=For%20example%2C%20if%20someone%20asks%2C,an%20agentic%20RAG%20system%20might) [\[25\]](https://www.glean.com/blog/agentic-rag-explained#:~:text=a%20static%20workflow%2C%20agentic%20RAG,and%20personalized%20internal%20search%20capabilities) Agentic RAG explained: Smarter retrieval with AI agents

[https://www.glean.com/blog/agentic-rag-explained](https://www.glean.com/blog/agentic-rag-explained)

[\[10\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Specifically%2C%20the%20retrieval%20component%20becomes,different%20retriever%20tools%2C%20such%20as) [\[13\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Single) [\[16\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Specifically%2C%20the%20retrieval%20component%20becomes,different%20retriever%20tools%2C%20such%20as) [\[23\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Enterprises%20are%20moving%20on%20from,and%20the%20possibilities%20are%20endless) [\[29\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=,the%20leading%20frameworks%20for%20developing) [\[30\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=,for%20tool%20use%20is%20sharing) [\[34\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=The%20benefit%20of%20agentic%20RAG,more%20robust%20and%20accurate%20responses) [\[39\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=For%20example%2C%20you%20can%20have,public%20information%20from%20web%20searches) [\[43\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Language%20models%20are%20the%20main,this%20feature%20to%20their%20clients) [\[44\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=In%20June%202023%2C%20OpenAI%20released,executors%2C%20databases%2C%20calculators%2C%20and%20more) [\[49\]](https://weaviate.io/blog/what-is-agentic-rag#:~:text=Limitations%20of%20Agentic%20RAG) What is Agentic RAG | Weaviate

[https://weaviate.io/blog/what-is-agentic-rag](https://weaviate.io/blog/what-is-agentic-rag)

[\[26\]](https://docs.langchain.com/oss/python/langgraph/agentic-rag#:~:text=Overview) [\[27\]](https://docs.langchain.com/oss/python/langgraph/agentic-rag#:~:text=In%20this%20tutorial%20we%20will,will%20have%20done%20the%20following) Build a custom RAG agent with LangGraph \- Docs by LangChain

[https://docs.langchain.com/oss/python/langgraph/agentic-rag](https://docs.langchain.com/oss/python/langgraph/agentic-rag)

[\[31\]](https://lancedb.com/blog/agentic-rag-using-langgraph-building-a-simple-customer-support-autonomous-agent/#:~:text=What%E2%80%99s%20LangGraph%3F) [\[32\]](https://lancedb.com/blog/agentic-rag-using-langgraph-building-a-simple-customer-support-autonomous-agent/#:~:text=There%20are%20many%20tools%20available,with%20the%20following%20internal%20components) Agentic RAG Using LangGraph: Build an Autonomous Customer Support Agent

[https://lancedb.com/blog/agentic-rag-using-langgraph-building-a-simple-customer-support-autonomous-agent/](https://lancedb.com/blog/agentic-rag-using-langgraph-building-a-simple-customer-support-autonomous-agent/)

[\[35\]](https://www.ibm.com/case-studies/comparus-gmbh#:~:text=The%20next%20step%20is%20to,involved%20and%20the%20data%20repositories) [\[36\]](https://www.ibm.com/case-studies/comparus-gmbh#:~:text=integration%20of%20services%20and%20back,involved%20and%20the%20data%20repositories) [\[38\]](https://www.ibm.com/case-studies/comparus-gmbh#:~:text=50,in%20queries%20to%20the%20bank) Comparus GmbH | IBM

[https://www.ibm.com/case-studies/comparus-gmbh](https://www.ibm.com/case-studies/comparus-gmbh)

[\[40\]](https://qdrant.tech/documentation/agentic-rag-langgraph/#:~:text=how%20to%20build%20an%20Agentic,search%20into%20one%20seamless%20workflow) [\[41\]](https://qdrant.tech/documentation/agentic-rag-langgraph/#:~:text=For%20web%20search%2C%20we%20create,effective%20tool%20using%20Brave%20Search) [\[42\]](https://qdrant.tech/documentation/agentic-rag-langgraph/#:~:text=The%20search_tool%20function%20leverages%20the,key%2C%20and%20returns%20the%20results) Agentic RAG With LangGraph \- Qdrant

[https://qdrant.tech/documentation/agentic-rag-langgraph/](https://qdrant.tech/documentation/agentic-rag-langgraph/)

[\[45\]](https://huggingface.co/learn/cookbook/en/agent_rag#:~:text=Since%20we%20initialized%20the%20agent,with%20your%20own%20as%20needed) [\[46\]](https://huggingface.co/learn/cookbook/en/agent_rag#:~:text=%3E%3E%3E%20agent_output%20%3D%20agent.run%28,a%20model%20to%20the%20Hub) Agentic RAG: turbocharge your RAG with query reformulation and self-query\! \- Hugging Face Open-Source AI Cookbook

[https://huggingface.co/learn/cookbook/en/agent\_rag](https://huggingface.co/learn/cookbook/en/agent_rag)

[\[51\]](https://www.matillion.com/learn/blog/agentic-rag#:~:text=What%20is%20Agentic%20RAG%3F%20How,the%20entire%20information%20retrieval%20process) What is Agentic RAG? How to make AI work smarter, not harder

[https://www.matillion.com/learn/blog/agentic-rag](https://www.matillion.com/learn/blog/agentic-rag)

[image1]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAjAAAAEYCAIAAADNhFv+AAArPElEQVR4Xu2dsa7jRpaG5wEmq0eZ6D6CDfRDOGkM4HBgGJ0asHNnTgwnfocOGhM421BowNGdeHu7kwWcCBsssDU8q+Pq+li8FMUqFskf+HBBFYsUi0f6v0uKov5y/Z//FUIIITbnL2wSQggh2iMhCSGE6AIJSQghRBdISN1x+Y//FEKIY/P8/IHpJyH1BcsmhBCHhAEoIfUFayaEEIeEASgh9QVrJoQQh4QBKCH1BWsmTsK//uu/RRu488UmMAAlpL5gzcQZeH7+wNwUlYh7myUQ7WEASkh9wZqJM8DQFFVhCUR7GIASUl+wZuIMMDFFVVgC0R4GoITUF6yZOANMTFEVlkC0hwEoIfUFaybOABOzH969fR/++kX8G+Fc4+lvf2djz7AEoj0MQAmpL1gzcQaYmF0RheTTqZZ++ek3m3Ah7eXqDJZAtIcBeLeQ4ktz4uEo33/3a9by6stv2W0ZcQOM9EYU3MhIfPOkjfZ/n5Gtk2TL1oM1E2eAidkVLqT4zo1/v379ozfa3/QIyeZ2Dksg2sMAXCIkT+fogPhC9On41x/adPowW0mqgWis2DO+1m3NcVX+LG+++Tl9yHVGr/g603Yjvje8Pa4h7ZP199XGZ/QOJs44K05bh7ipvjHxr1ntOig2Ple6wmWwZuIMMDG7woWUYodH8W985ZuQ7O2wi9N3LIFoDwNwiZA8yj2mrzchjVphFI9vX0NcNsa9C+Y6JL53S9tTKCSbSP+OYp7zDtEoEwvaw2wP+pGfzf346Y907jJYM3EGmJhdEW5CCsN/Y/YwDB8s2bRJKL5b7X3ENfQGSyDawwBcIiSf5hHShAAcO8qxw450kTAIKdxOoxkvHnbEt4SpxVcSBk36ylNPjG5easRrYh1bVTor3bD4pJmQVoE1E2eAiSmqwhKI9jAAFwrJI3iBkMLwT5afQEtD387dpZ3nCCl96Cu3s2p+3ONzuQbHzxk62eFXtm0SklgLJqaoCksg2sMAXC6kLKOtJYvm0aR2x6RnyQyL+DB8eGOzKKRsnZkz0v7WEo+QStsWkmOpdJHr8ElSOst62oRvm4Qk1oKJKarCEoj2MADvFlI9wnBKmu0tWeVzoEdgzcQZYGKKqrAEoj0MwC6EZB8dsb0lfpZvW1gzcQaYmKIqLIFoDwOwCyEJhzUTZ4CJKarCEoj2MAAlpL5gzcQZYGJO4J+Jisi9e89gCdrw9Le/x7/ff/crZ50QBqCE1BesmTgDTMwSYeuT272x7GZFLEFtzJ3TLWeD1ZSQ+oI1E2eAiVlCQiLh/q/isgT1kHhKsJQSUl+wZmcm3L5VZic6Upad9Mii4d6kePf2fdZy7xpKMDFLSEikWyHxdVtirRfSvmApJaS+YM3OjL9LfcI8FMXw5pufqYdItJd1sIfZRPa25xq8xYUXW2ydl2HlXGQVmJglJCTSp5Dm28h49eW3bDw2LKWE1Bes2ZlJheQmsEY3U9r/69c/XgZtxCxwi6S5wP9DR4+ZbBGbTv9mT2fbwHUugIlZQkIivQnpXhWdFpZSQuoL1uzMpBoIw40NjUtZSN4h3C7BCsNdNniEZB1sbjze8jVwPf43ezpfQ9q4DCZmCQmJ9COkZWeSyUmUxlJKSH3Bmp0Zz3q3gt0C0aZfffktDZEmgh/BpEv53OyQy9Rip024iC9Y6bwKE7NEkJBA6EBIJ1HIurCUElJfsGaiJamxWsLELCEhkR6ENBP7v2emvSr999MPLKWE1BesmWiDJYWEtEf2IiR/jc18pUlIYmNYM3EGmJglJCTSv5AyFc3UkoQkNoY1E2eAiVlCQiI9C4kGGoULXiQksTmsmTgDTMwSEhLpVkgUzwRcXEISG8OaiTPAxCwRJCQQDiok++LBgWEpJaS+YM3EGWBiZlhg2QRfNtfk94vt1hLsUBV/9kpMrz9sJ6Tp6+VS33z1z3/Yj02nLdNCKh0hxfqOusq+DO5fqptg9OlIfJZKtyYxWEoJqS9YM3EGmJjEepaE5HiHd8nvL9v08/OHODf+vQ6/SGmz7GFKuuAlSQ2bThf3nhZw2XrSp0h/iznrGefa0Pxhth7f5hJhOyFdJp2UuseE9MUPr91D1nivkPzpfBG/KYl98c47eLvPivUywbhmvE9s4bd646pGN2wtWEoJqS9YM3EkPH0egS8bg4cR1jnGSvwb/9v1FvsbM4grjP9fZytJW+KqYkqaaWxBrtbwaXsWWzZ6JS4ep1M/sWe2KrNRukiG75kNYa3Tcpt7RplYw6iQsp72ML19SWqRcPuu9+XztVmHVE7Wkq6cflodllJC6gvWTByDkNyOj/BfeOLr4cvGsFyz6ZgmxvXzYw7r4N3SRbI+6UoiYThMMSHZCk0to6u1aVvQNfNquLPGxNPZ3THSLbelbCO5YLoG7q5pWILFzD9CGsX7cPE5QkqfPRWS3/5qdM1stJa03TdszjnAZbCUElJfsGbiALx4Lp6JyQC12A3lXLbsZnvpCMkEM7pIKhvvb6tyIVkjV5st4tMmJOufnhX0niYkb8/mclbah3tsGpZgMQHhns4y4thNP1/88DokfvIOoysZFVJ2ys7+Ws9USP56W3yExHODq8NSSkh9wZqJCSzCGpCejr+X0c+fM5iYJUI5lzPSSxvS6ewzJJLOcnOMnjFLvULiekaXmuYyllPThE2FNAFfSBNw8VEhGen/N6UXZ3rOzaezf4xKy7aBpZSQ+oI1EyXC7GhehdHIeBE72cX2DCZmicajroHlL9sXEw4qpDn/yuwallJC6gvWTIwSVk20mYymxjQzF2Filthk4J0TehWSQfekpB8CZYcvE0dIx4CllJD6gjUTo2ySyzPtkm0nGwkTs8QmA++croQ0WvH00owU9rTO2cRRYSklpL5gzcQom+RyKUEmmLgEK4WJWWKTgXdOP0KafoXMsZFhKpKQxMawZmKUTXJ5OkRGkZAa0IOQ5l8dMP9VNL/nTmEpJaS+YM3EKJvk8oKAkJAa0IOQLmt/k3TmK2fXsJQSUl+wZmKUGrlsJ1LYnnbglkwzM1aYmCWmt/CcdCIkY8GLJOPxNewFllJC6gvWTIxSI5ftu4psdxYkhYTUgK6EdHnMKNNfoD4YLKWE1BesmRhl9Vy279LHv37TGrIgaCSkBvQmJOPeV8u9/Q8ASykh9QVrJkYp5XLAlbUGe16HWwnY/Wzsod3Vxme9+f1TJqcFkSEhNaBPIRlzXgALXlfHgKWUkPqCNROjlHI5jN3IsnTHNrv1ZPrQpz9++iMKKVtqQXDMyaOLhPQYPQvJKN1zYebL46iwlBJSX7BmYpRSLo8Kye5iyc7O03D70TDcBPN6u28bF5GQOuT5+QP30ouwBA1IXwwlRZ0KVlNC6gvWTIxSyuVlQroOTrKefj9QLtKDkGLn6V+rOxXPw08Oci+9CEvQBr8hN2edEBZUQuoL1kyMQltcyzaaI6SYFF8NJ/f8IyUu0oOQxCqwBKI9fBtKSH3BmokMs0Jmi4CrGEpkP8pgjfYw/QwpiqTPz5DEKrAEoj3pm8uQkPqCNROkdJHCvWS/CJcK6fn5QxSSfbbkmJDu0pKE1CcsgWgP35ISUl+wZsfG1DIztbOluPcWY4dNcbXpj3PzKexwitszwcyhMTFFVVgC0R6+EyWkvmDNDsy7t+/vzXcjPc+WEduzz/ztWUr9Hbuo4YsfXpuNbFVZH3MniYuM/jW4/YSJKarCEoj28G0oIfUFa3ZU5t8dOcMinra4Jp8kvfnmZzaOLpJ2s8sfpoUU7jSohNQnLIFoD9+GElJfsGZH5d5kz6At7Fuu02SLPA2n/rw9/QwpNtqvj6f9gz5DOgosgWhP9n68Ski9wZodkrsyfRTa5ZocDI02cpF4lBYl5F88SoUUbfTm90+RbFXckmlqCMk9KuKu4P6ZA0vQhnj8ra/EOtn78Soh9QZrdkjC/cmeEWCXa3KQlDZ6eLF/GE7u+Tm6VEivht+c9lnen1syTQ0hjY7lnFhluYtehCVogJ+mfvf2vbR0kZD6hzU7HqYNtt/F6qEcM+KLH16X1GUs2OzVhTSxeacl1o47ahqWoCrxNc8PTdf9Qb89wlJKSH3Bmh2P+deeTVAjl+2iBrY7ElKfLDhIYgkqQQ9l2P3m2X4GWEoJqS9Ys+PRrZBeRELqkz6FdFrNzIellJD6gjU7HhISYWKW2GTgndOnkBYQj5bYeGBYSgmpL1iz4yEhESZmiU0G3jmHEdJljet9dgRLKSH1BWt2PCQkwsQsscnAO6cTIZ3506BlsJQSUl+wZsdDQiJMzBKbDLxzOhHS6hxebyylhNQXrNnxkJAIE7PEJgPvnL0I6enzbzSzQ8bhP1JiKSWkvmDNjoeERJiYJTYZeOf0L6TUQ/OddPgvz7KUElJfsGbHYxUh2T+b3IH1CPf/TMZl9mfUTMwSjUe9CzoXUnZgNN9JOkISG8OaHY9VhGTw7V0PPvscZi7IxCwRJCQQehXSm29+5gtplNF3hIQkNoY1Ox4rCmkXzHESE7OEhES6FRLFMwEXL52ye/f2/YSrSkulzHkDxvVEqt7fiKWUkPqCNTseZxPSZYaTmJgZT7fbWocDCSkGKxsXELYT0vSdgVLfPA0/20gP3SukeNTlK7fL8LJt8FWlLrHp2N8W8ev30vu9Zu7x9dR7t7KUElJfsGbHQ0IiTMwM+xziXzOElP1gbkp6O/MeeHEs1sfgrLQP99g0LMEypn/12Dfef/vRW6wx/XiJi48eBmU9o5/sxGDWIf6NsrE12HQYfuLLrOPtvqz34RONbsYqsJQSUl+wZsfjhEK63LKJ7QYTcxTLL75srrdwjx38YcwXn44xZBPW7dXwC+vZsqMLmt7stwpdddbf18aVXIct8R/v+PjpD58bV+IL2t90Ln8UcQ5hOyFdksMOYiMNiZBSM9m09+Hio0dIWU8uaGuzrQrDT6hwJWy09aRrC8PLZvQ+5WvBUkpIfcGaHY9zCsmJb2/bAxbZPjEHyxq+bK630182N+1TmubD6+fn0GxuerzFlhKpF72RqyptWzY9MWrvw301E69FVoisfWLWq6EuLPQFQhrF+3DxUSG5HmwR+5saMbbEBf3Mnvd/lUjIptP1p2tLW7LGdWEpJaS+YM2Oh72N2X5m+C88CfNO2V0R6KPTfOi8Go5sONda5giJy15vC9rv81qHiW27C9szd8ESLGYir8OYkNKH3mF0JaNCMlIDlY5g+BlStmDWpz0spYTUF6zZ8ZCQCBMz42nGRQ1ZvvtDn366nfFL53IlXNBD85oIaWIlPtfP/vmCdlLOV5v296W4noknsj7cY9OwBMsoycDwjZ8DF0+PaQ4JSykh9QVrdjwkJMLELBEmo3kvrDuKsJ2QpqF1JuDiE0dIx4CllJD6gjU7HhISYWKWCKtG+SbYFRYrEroUkjmG4hklu8LNkJDExrBmx0NCIkzMEmH/Qlqd0JmQspc39ZOSfaiTPtQpO7ExrNnxkJAIE7OEhET6EdLENQL+4Zkz8flTGI6WJCSxMazZ8ZCQCBOzhIREehDSzNNrpiK/JnuCKLDDv01YSgmpL1iz4yEhESZmCQmJ9CCk+UwcGGXMlNx+YSklpL5gzY6HhESYmCUkJNKJkN5N3vP0LuZLa9ewlBJSX7Bmx0NCIkzMEhIS6URIxsTHSHOIb42T2OgiIfUPa3Y8JCTCxCwhIZGuhGTEQ6XSDe5KPGiyPcJSSkh9wZodDwmJMDFLSEikQyEZ84917rXXMWApJaS+YM2Oh4REmJglJCTSrZAu+E4SidI6/MULJVhKCakvWLPjISERJmYJCYn0LCQj4C4Ml7MeFaWwlBJSX7Bmx0NCIkzMEk/J7xiJ6yIb/au5kDJiEWWji4TUP6zZ8ZCQCBNzgqfkZ0ZPztPtJuj3whKI9jAAJaS+YM2Oh4REmJiiKiyBaA8DUELqC9bseEhIhIkpqsISiPYwACWkvmDNjoeERJiYoiosgWgPA1BC6gvW7HhISISJKarCEoj2MAAlpL5gzY6HhESYmKIqLIFoDwNQQuoL1ux4SEiEiSmqwhKI9jAAJaS+YM2Oh4REmJiiKiyBaA8DUELqC9bseEhIhIkpqsISiPYwACWkvmDNjoeERJiYoiosgWgPA1BC6gvW7HhISISJKarCEoj2MAAlpL5gzY6HhESYmKIqLIFoDwNQQuoL1ux4SEiEiSmqwhKI9jAAJaS+YM2Oh4REmJiiKiyBaA8DUELqC9bseEhIhIkpqsISiPYwACWkvmDNjoeERJiYoiosgWgPA1BC6gvW7HhISISJKarCEoj2MAAlpL5gzY6HhESYmKIqLIFoDwOwrpDCX79g43mwX7Rk+wSs2fGQkAgTU1SFJRDtYQBWFNLJbbQM1ox8/frHCNsz4v5nI3n39n3WMmfljzBfSDbSOdvz5puf2UiyVc1Z8wQzt20OTExRFZZAtIcBWFFIwrhLzKwZiSv85aff6JusZWboZ0J69eW3XPO6zBeSjXR0sNkaqNVRsvVwtXdRKsQCmJiiKiyBaA8DUEKqTg0hpQ9jNFtL/Pv9d79aiwelNfp0+jf2if/gZ1Fuc63RAzda6jIchcTpOMukFYmLxw72pPO5S0jphG+PrcSe1x7Gdpu2QyXbTpvwTU1XOPoUcVy++OgOjBPpYH1LsnUugIkpqsISiPYwACWk6sSYY2MJ1ox4yNp0TF4P36zbZTitZAox/aTdYrstPvoUlyRqzUD2RBbcabd7uUtIRnxeG0jEls3WYELyLbRl0w6pvbKWdA/YeuIsf6LRtRkhcdWDMDFFVVgC0R4GoIRUnRpCyv6m7aPdPHNtwg6hbG4ax57ymeGy83gthWQT8Rk5hLSnDcf+erfpXeTTaWNqu3QnjI50tHEZTExRFZZAtIcBKCFVp5KQ/OP0p9spuyzoPUnTzzlswsLa2lMhZQnrp+bMQHY0EJ83E9K9ubxASByLb5Xhfv1l+MzJGv0Qx042piu8fL4DbZYtzidKF0yf1LYhXedimJiiKiyBaA8DUEKqzupCaoaH772fEk0zX0jtSX3TEiamqApLINrDAJSQqrNfIVWiZyFtBRNTVIUlEO1hAEpI1ZGQMiQkwsQUVWEJRHsYgBJSdSSkDAmJMDFFVVgC0R4GoIRUHQkpQ0IiTExRFZZAtIcBKCFVR0LKkJAIE1NUhSUQ7WEASkjVqS2kd2/fPz9/4KoqEZ8rvVJ8AWsJKdxzC4zHWeXy7hJMzBKxc8tyd07cFbEu3EsvwhKI9rCgElJ1agupcS5fH47mVYTUftTXhwc+AROzxCYD75z4cuKOmoYlEO1hKSWk6khIGRISYWKW2GTgnbPgIIklEO1hKSWk6khIGRISYWKW2GTgnSMh7RSWUkKqjoSUISERJmaJTQbeORLSTmEpJaTqSEgZEhJhYpbYZOCdIyHtFJZSQqrO7oRkVy6x3Xkwl7sVUhjur8r2tAO3ZBWYmCWmt/CcSEg7haWUkKqzOyHFFX71z398/PQHZ3kHbsZ8uhVSHHWE7c6DA5+AiVmixsD3joS0U1hKCak6+xKSHSXEXI7HSaXvuzyYy30KKZYpjjr+/f67XznXeHDgEzAxS6w+8AMgIe0UlrILIVkIbs5EEj3CJkLi6IzRjQm3n//xlrRblMeb3z9l/bkZ86kqJA7ZYM9IHPWr4af/7OHXr39MZ8VRZy+JBwc+AROzRGksZyZISPuEpdxeSDGb2LgJBxOSnYDKKHWO+ZsWIt3mOHdfQhod9Wj/bNSpkKKl4qjTFls5t2QVmJglRgdyciSkncJSbi+kft5gMZ7Y+Dj9C+l6k7Hnr3UrdX4wl9sLaWLghmkp3I4g7fMzLvLgwCdgYpbgVgkJaaewlBLSn0hINmHLThwvPpjLHQrpOjjJevrVHFzkwYFPwMQswa0SEtJOYSklpD85jJDsum2GsuXym29+5vNSSBOb/WAu1xNSadQ2cPYfXdZ7cpEHBz4BE7MEt+pBbIXhdlaz3in00jUyjxMkpH3CUkpIf7IvIb17+97uup3uQIuVmaRLlS5qiE8RCp8hxb/Lbvv9oJD82bNNmklaZRu1ryr9xOhpuJTDZ2UD51Y9CBOTARqG2M026XGs1mGopk34LJu23cJ2tlyHs502batNl7W/o/8PPYjtmbtgCUR7WMo9Cal0Zn8t9iWky+Ck8LlalhGGmE7j+MWLGsIDofygkC7DGh4f9fUmJH+Y7oH473wcdXa4EDs/uOUlmJijrFLuCdxJDvtck69Ox9dJ2pNLpdM6QhIZLOVuhJR2s7j0/+y8g0/HZIlzXTAzz0KcVkjX2yk7X5XtsdKW25Nye2YSV/tgrK8lJMdKH1droZm9tJwHBz4BE3OUtcqdkb6Jrrf//NL2K/5HyeaG5NAza7/edq+EJDJYyl0KyabT1PDXehYldx1U7U5IYTjNMjq6MJZc9v8sO1+Tz5BswekPXex5l52vu6xxhDQ6Ot+2LPhmavtpuKjhix9ee724iK2H2/M4TExiPblVj+PrTCfC7Zt5Np0+rz20/WzT/r7j/wq+rIQkMljKXQqJR0jxbzwqMq64fNm/+TjNvoQUbsnIHWgR4EEw0ehQSBM7zZ7agp4b9iIPCsmWHR2FDzD9oGJ64Gk3u6hhWki+AevCxMywp7YJbvzJCRLSPmEpdyOkKw53bCJb3M41uZBKBxCj7EtIDgeYRvAo7B/3WHqdt2+zHVSt+/3QB4VkcBRxIznS6YHbv/Peng4zDMcH2SLhsYFPwMQswVGIICHtE5ZyT0Iy7tXG/PXfu+aZbCskb4wHDWw0Yi6XrrKzubyogZsxn0pCsg3jAEf3hmGXcvhHJqmQoo3iqNcd+ARMzBIchQgS0j5hKfcnpLuw7GP7KIcRkl16G3DnOmvkN17NRul60tNWfIoHc7mekPwgKdtaNvqs6GkfbHad4egO5JasAhOzxOhATk6QkPYJS3lwId3FYYT0CHFrYy6nn+2TB3O5npAe4d3b93HUJXUZDw58AiZmiYnNOy0S0k5hKSWkP5GQjDB8vM/2tAM3Yz59Cumq30PaLRLSTmEptxfSNTmpYm82+zB5E7htj7M7Ib1IeCyXuxXSizw48AmYmCU2GXjnBAlpn7CUXQjJCbf7lxwJCSlDQiJMzBKbDLxzJKSdwlJ2J6Tjvd8kpAwJiTAxS2wy8M6RkHYKS9mdkNi4dySkDAmJMDFLbDLwzpGQdgpL2ZeQDomElCEhESZmiU0G3jkS0k5hKSWk6khIGRISYWKW2GTgnSMh7RSWUkKqjoSUISERJmaJTQbeOfEtxh01DUsg2sNSSkjVkZAyVhHSE+4qXZtQ7ceQLhLSAzw/f+BeehGWQLSH1ZSQqlNbSJfBSS3hBtzFKkIyuG314LOvCBNzAm7bmbl37xksgWgPA1BCqk4DIS3D3sztWVFIh4GJKarCEoj2MAAlpOpISBkSEmFiiqqwBKI9DEAJqToSUoaERJiYoiosgWgPA1BCqo6ElCEhESamqApLINrDAJSQqiMhZUhIhIkpqsISiPYwACWk6khIGRISYWKKqrAEoj0MQAmpOhJShoREmJiiKiyBaA8DUEKqjoSUISERJqaoCksg2sMAlJCqIyFlSEiEiSmqwhKI9jAAJaTqSEgZEhJhYoqqsASiPQxACak6ElKGhESYmKIqLIFoDwNQQqqOhJQhIREmpqgKSyDawwCUkKojIWVISISJKarCEoj2MAAlpOpISBkSEmFiiqqwBKI9DEAJqToSUoaERJiYoiosgWgPA1BCqo6ElCEhESamqApLINrDAJSQqiMhZUhIhIkpqsISiPYwACWk6khIGRISYWKKqrAEoj0MQAmpOhJShoREmJiiKiyBaA8DUEKqjoSUISERJqaoCksg2sMAlJCqIyFlSEiEiSmqwhKI9jAAJaTqSEgZEhJhYoqqsASiPQxACak6ElKGhESYmKIqLIFoDwNQQqqOhJQhIREmpqgKSyDawwCUkKojIWVISISJKarCEoj2MAAlpOpISBkSEmFiiqqwBKI9DEAJqToSUoaERJiYoiosgWgPA1BCqo6ElCEhESamqApLINrDAJSQqiMhZUhIhIkpqsISiPYwACWk6khIGRISYWKKqrAEoj0MQAmpOhJShoREmJiiKiyBaA8DUEKqjoSUISERJuYEsXDCuXfvGSyBaA8DUEKqjoSUISERJmaJWDW+bM7M8/MH7qUXYQlEe1hNCak6ElKGhESYmCUkJBL3CXfUNCyBaA9LKSFVR0LKkJAIE7OEhEQkpJ3CUkpI1ZGQMiQkwsQsISERCWmnsJQSUnUkpAwJiTAxS0hIRELaKSylhFQdCSlDQiJMzBISEpGQdgpLKSFVR0LKkJAIE7OEhEQkpJ3CUkpI1ZGQMu4S0tevf4ywPWPxWN69fc/G+cTF549lAiZmCQmJSEg7haWUkKojIWXcJaS4kb/89Bs3NWuJO5nLvsjomqf5/rtf04elzbsXJmYJCYlISDuFpZSQqiMhZdwrpHQ6Lmgt8a+5Ie7eeAjl3WKjd7gMz2XTURt80tgeF7f1xLmmFl/QlrJu1hiPh1LzrbgDmZglQjUhffz0h430OkS8T/dPkJD2CUspIVVHQsq4V0jugyieqIRIelBiOrGH8W+cay12Ls67xYel8fqy/tDWM7pIeoTEuYthYpYI1SRh47X120S951qXICHtE5ZSQqqOhJRxr5Cyv2n7BUK6JB8L2UTsYJ9CZePlyTefmNgz6VJ2/JQuuxgmZok2krCd0Oa5HidISPuEpZSQqiMhZSwQkh/u+Ck7P02XCik7eEon+ElP9tDO9RmX2yk7bidXEuvLbvfCxCwR1pbEx09/2JUjhjX6rrgOR06xDxfshyAh7ROWUkKqjoSUcZeQmvHmm59tYpNtY2JmWLFsgi+bR3D3pBIqTadEx7vA4jTXbFzGcmddJKSdwlJKSNWRkDL6FNK2MDGJ9aQYHmSmkGLJ0qXiYZNNWLv99cbrcOBlExOuWgsJaaewlBJSdSSkjDMLyc4EPghfNpuQbsnTcI1inPj+u1/jsab56fn5QxhOll4raylISPuEpZSQqiMhZZxTSGG4co/tBhOT+Hr4snmEVHI+TQuWntfaY0GjhyJxjPbxnnewC+654IoECWmfsJQSUnU6F1J7N5xQSHbBOtsdJiYD1GK3JIbFuGyiTnyaNsqe1x1j7Xbkd719sOSd47QdG62+2SlBQtonLKWEVJ0OheQRs4kYzikkNqYwMUusnuwuGxOJTfsrxIm6Ki14vfkpDEeBdqWDL1L1ZJ0RJKR9wlJKSNXpUEhG0Cm7+vidI6ZhYpZwB6xOKqR9ISHtFJZSQqpOAyG1DJE58TrNWkIKw92DuIU1sNNZ3IYXmbkUE7NEvVqPHiGxW4dISDuFpZSQqlNbSO1TY2bIllhFSGHsJFJVZh7rcDvZSJiYJeqVW/eyE41hKSWk6khIGWsJiRtWmwUDnzlSJmaJqgN3CdlFCo2VvxgJaaewlBJSdfoUUlzqq3/+Y/Gy3Iz5SEiEiVlik4F3joS0U1hKCak6HQrJbGRw7ossyOUUCYkwMUtsMvDOkZB2CkspIVWncyEtW5ybMR8JiTAxS2wy8M6RkHYKSykhVac3IVn/GJRf/PDapgPuVDbNglxOkZAIE7PEJgPvHAlpp7CUElJ1thXSx09//PLTb/bjC1nP7KFd9fvm90//ZvLT7AW5nNKtkF48Xlww8JkjZWKWmN7CcyIh7RSWUkKqzrZCCsPdLVMnTfD/NjqlkGKZ7BzmxMHigoHPHCkTs8TqAz8AQULaJyzlLoVkibYt8zUzv+e1gpBSG2WzRltMSJyVdeNmzMd2INvvYnoLZ2Ia9h9N8F/3uQ7fOnq63Z8t7c8tmWbmSJmYJVYZ+MGQkHYKS7k/IYXkA/ltmRkN2wop5fn5Q8Qfpgv69FP5+CDtzM2YT1UhheHzsAxrZOfoafvBWXuYCilOm5uzlXNLppk5UiZmidLAT0t8SXMvvQhLINrDakpIy5kZDf0I6Tq8ey12n4aLGuLfj5/+SLdwNLgzFuRySm0hsVJxgKP9w3CE5JJOhWSzsqUWDHzmSJmYJWLn9L+Kk2M/ucS99CIsgWgPCyohLWc040hXQjLSfZjNaiAkO3/I9rsojbr08ij1N/wG1SG5Px4XWbDZqwvJMMUK7pmZsASiPXwnSkjLCQisUToXUrZ4AyFdhm1m412MjtoO+1gpDpPEI0Xr6T+XwEUWbHYlIYkHYQlEe/g2PJSQJmbVwAOLyZWyuZDC8L+kT6ftaTc7Mkg7l1iQy+TBlWQbaZs9h/TneazFD4nSU3ZRJOkPzaUDt78zkZD6hCUQ7UnfXMYxhWRB49P2j7N9ZPI0fMSdzYrT9i1Rm2XnQ+Is72YtfDo7hc2NTNlWSCG57Juzspa4qQ2usjPi9rBxDhbx01s4E9stUUjv3r6PxOHbRCQ+y+hFDfeOXULqE5ZAtIdvyQMKKe3wNFyfbdOmHJtIu3Gp0Wk+r8WTPcUEYfDZfMyatlqfHm206eloDv19D8lZth5banrUM3n1+cUO6RFSdJL93kTaP4xdwueF4F+DQyBMTFEVlkC0h2/JQwnJPWHJ7h8nxBY/Qkq7pRP87MHafW2vbmJLO/R/hJTeqSGbNdpiQkqjmYRFIhnFhDoztbOluGHX24nHjGiXy9ir37Hr1sxPXi8+RdAR0lFgCUR7+E48lJBsVmqOMKjIJ6yDaSmd9dXnQvKnsODLGtNuvkncTmdbIaVkZ+3SBX0jn5pc1PAgJSGF26HeaOPoIo5f1JAumPWxgd81fAmpT1gC0R6+DQ8lpGlcSGvBwBqlHyE50Uz+yVl2MNS/kNwK2VbZr4xPw4E8Dd/EsofZKTubm/Xn9kxTQ0jmYxGGAnH/zIElEO3J3o9XCekRAgJulA6FlO6HbFb/QrKI56jnfEjGRaLGRoUU20cvauD2TFNDSBzIabGyche9CEsg2sOCnkhIqzMzFzoXUrZ4/0IyRkc9Kh5v5JUa2UdrqZCipXi14YKBry6k0YGfnHg4yx01DUsg2sNSSkjLmRkNmwvJrviy6bRztqB9wsRAJwtyeXVe3Mi7sP1jY/d7rZIFA5eQGhDuP0hiCUR7WEoJaTkzo2FbIYXbZd+8/IwLPt2+fMNZ2YLcjMZMb+ECnp8/WFk5y1kwcAmpARLSTmEp9yck+3bIJpiEHG7bKJ0IKbvEzmZlLf/+TGUQ0vSJu3B/Lq8ON/5x0s+TRlkwcAmpAUFC2ics5f6EtBUuJM6aZlshvXv7fsH3kM4ppBdZMHAJqQES0k5hKSWkOwj3HBg52wopJbvCO11w+puwGQtyeXXmj3pFFgxcQmqAhLRTWEoJ6T4WxEE/QjKenz/Yvdq+Gr5EfNfmGQtyeXXuHfUqLBi4hNQACWmnsJQSUnXuSnzW7EUWJFQofw9pDgtyeXUWjPpxFgxcQmqAhLRTWEoJqTodCul6c9LiZbkZjVm25Q+yYOA9C+npdscHzkqxPtOXe2yLhLRTWEoJqTp9Cum66PSjsSCXV2fxxj/CgoHPXISJWWLFgZtppp00p8/mSEg7haWUkKrTrZAWMzNkqxKSH9Zrg90rj1syzcxFmJglVix3KpuQ3ObcsDvZp3ANnRAkpH3CUkpI1aktpEtbJ81M2AaEsbsBVcK+/cZtmMOcBZmYJVasdeab1DpsH33ema9tu/lFvX8ggoS0T1hKCak6M9+0BmsmDkB4yUlMzIyn222tR8WwDCpnGq7hivsBWotN2PWc6dNx8VUIEtI+YSklpOpISCKsISSL3RVjncqZJl2Wx6beLUrIroCw34aPPe33D7M1rEiQkPYJSykhVUdCEpfBSaGsJSbmKKYlvmyWQeVk+GV4Rrqs38sjneXHQ/6at5+VkpDEKCylhFQdCUmk/PLTbzHNjVfDjdhtYg4UwyNQNv4w883E88bDIO+cCslf9hKSKMFSSkjV8XfmHFgzcQaYmMQ+Rlox1kdlEz6/fHG0j8FPj7IjJF9QQhKjsJQSUnV6E1LcnvRh+Pw8UvZQtIGJmVH7ogbOnd9ncySkncJSSkjVkZDEizAxS6wohjmymdNncySkncJSSkjV6U1IX7/+MX1oWWPTdhKGi4jaMDFLrCiGObLxDv5BUYdISDuFpZSQqtObkHiEFDFLpXISLWFilpiQx2mRkHYKSykhVeeuBGHNVodHSPb33dv3/lA0holZ4q6X00mQkHYKS1lRSPXuFLIv+j9CSickpE1gYpaQkIiEtFNYyopC0jsncu9N+1mzVbBzcSYb/zpLZiAJaUOYmCX0tiIS0k5hKSsK6TocHITh41D7otypCLh98hxYM3EGmJglJCQiIe0UlrKukMS9sGbiDDAxS0hIRELaKSylhNQXrJk4A0zMEhISkZB2CkspIfUFaybOABOzhIREJKSdwlJKSH3BmokzwMQsISERCWmnsJQSUl+wZuIMMDFLSEhEQtopLKWE1BesmTgDTMwSElLGqy+/5V56EZZAtIfVlJD6gjUTZ4CJOUH2u3lnxm+Cfi8sgWgPA1BC6gvWTJwBJqaoCksg2sMAlJD6gjUTZ4CJKarCEoj2MAAlpL5gzcQZYGKKqrAEoj0MQAmpL1gzcQaYmKIqLIFoDwNQQuoL1kycgefnDwxNUYm4t1kC0R4GoITUF6yZOAnMTVEJ7nyxCQxACakvWDMhhDgkDEAJqS9YMyGEOCQMQAmpL1gzIYQ4JAxACak7WDYhhDgYz88fmH4SkhBCiC6QkIQQQnSBhCSEEKILJCQhhBBd8H8flHIKlqSqkQAAAABJRU5ErkJggg==>