<!DOCTYPE html><html><head>
      <title>article</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex.min.css">
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<h1 id="introducing-vertex-ai-vector-search-20-from-zero-to-billion-scale">Introducing Vertex AI Vector Search 2.0: From Zero to Billion Scale </h1>
<p><a href="https://en.wikipedia.org/wiki/Vector_database">Vector search</a>, or Vector database, has become a foundational technology for modern AI systems. By representing data as high-dimensional embeddings that capture semantic meaning, it powers everything from <strong>semantic search</strong> that understands user intent, to <strong>recommendation engines</strong> that surface relevant content, to <strong>Retrieval-Augmented Generation (RAG)</strong> and <strong>AI Agents</strong> that ground LLM responses in real, up-to-date information. Major tech companies including Google rely on this technology at massive scale to process billions of searches, recommendations and groundings daily.</p>
<p>Yet building production-ready vector search remains challenging. Google recently released <a href="https://cloud.google.com/vertex-ai/docs/vector-search-2/overview">Vertex AI Vector Search 2.0</a> to change that—a fully managed service designed to eliminate the design and operational complexity that slows teams down.</p>
<p><img src="assets/vs20_post_thumbnail.jpeg" alt="vs20 intro"></p>
<h2 id="why-vector-search-is-harder-than-it-looks">Why Vector Search Is Harder Than It Looks </h2>
<p>The concept is simple. The implementation? That's where things get complicated.</p>
<p><img src="assets/vector_search_challenges.jpeg" alt="Vector Search Challenges"></p>
<p><strong>The embedding generation.</strong> Vector search requires converting your data into numerical representations (embeddings) that capture semantic meaning. This means you need to call an <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings">embedding API</a>, batch your requests, handle rate limits, and store the vectors. Every time your data changes, you re-run the pipeline. It's infrastructure you have to build before you can even start searching.</p>
<p><strong>The feature store.</strong> Many vector search products provide only a vector index that returns a list of item IDs for each search. To serve full search results to users, you need a separate <a href="https://cloud.google.com/vertex-ai/docs/featurestore/latest/overview">feature store</a> or <a href="https://cloud.google.com/bigtable/docs/overview">key-value store</a> to retrieve the actual item data—names, prices, categories, image URLs in millisecs—by passing those IDs. In many cases, you also need to implement complex filtering on item features such as price, category, or availability. This means building and maintaining two different services: one for vector search, one for data retrieval and filtering. Every update and query requires accessing and syncing both systems.</p>
<p><strong>The index tuning.</strong> To build <a href="https://en.wikipedia.org/wiki/Nearest_neighbor_search">approximate nearest neighbor (ANN)</a> indexes with millions of items, you need to make <a href="https://cloud.google.com/vertex-ai/docs/vector-search/configuring-indexes">expert decisions</a> to get the best performance: How many items should each index node hold? What percentage of the index should be scanned per query to balance recall against latency? What shard size matches your dataset? These are ML infrastructure decisions that have nothing to do with your actual product.</p>
<p><strong>The hybrid search.</strong> Semantic search excels at understanding intent—finding "Board Shorts" when users search "men's outfit for beach." But it fails on product codes like "SKU-12345" that have no semantic meaning, and struggles with newly coined terms or brand names the embedding model has never seen. Keyword search handles these cases but misses semantic context. Users need both, which is why <a href="https://github.com/GoogleCloudPlatform/generative-ai/blob/main/embeddings/hybrid-search.ipynb">hybrid search</a> has become essential. Building it, however, is far from trivial. You need a full-text search engine with tokenization, inverted indexes, or sparse embeddings—in addition to your vector search engine. Then you must run parallel queries on both engines, normalize their different scoring systems, and merge results with techniques like Reciprocal Rank Fusion.</p>
<h2 id="how-vector-search-20-solves-these-problems">How Vector Search 2.0 Solves These Problems </h2>
<p>Vector Search 2.0 on Google Cloud directly addresses each of these challenges:</p>
<p><img src="assets/vector_search_benefits.jpeg" alt="Vector Search 2.0 Benefits"></p>
<table>
<thead>
<tr>
<th>Challenge</th>
<th>Vector Search 2.0 Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>The embedding generation</strong></td>
<td><strong>Auto-embeddings</strong>: Define which fields to embed in your schema. Vector Search 2.0 calls Vertex AI embedding models automatically—no embedding pipeline to build or maintain.</td>
</tr>
<tr>
<td><strong>The feature store</strong></td>
<td><strong>Unified storage</strong>: Your product data and vectors live together in Collections with an SQL-like filtering capability. One source of truth, one API. No separate feature store needed.</td>
</tr>
<tr>
<td><strong>The index tuning</strong></td>
<td><strong>Self-tuning indexes</strong>: The system optimizes index parameters based on your data and query patterns. Start with instant kNN search (no index needed), add self-tuning ANN indexes when you need millisec latency at massive scale.</td>
</tr>
<tr>
<td><strong>The hybrid search</strong></td>
<td><strong>Built-in hybrid search</strong>: Provides built-in full-text search without needing to generate sparse embeddings or inverted index yourself. Semantic search, keyword search, and hybrid search with Reciprocal Rank Fusion—all native, no external search engine required.</td>
</tr>
</tbody>
</table>
<p>In this post, I'll walk through the <a href="https://github.com/GoogleCloudPlatform/generative-ai/blob/main/embeddings/vector-search-2-intro.ipynb">official tutorial notebook</a>, which builds a fully-managed hybrid search using 10,000 fashion products from the <a href="https://console.cloud.google.com/marketplace/product/bigquery-public-data/thelook-ecommerce">TheLook e-commerce dataset</a>.</p>
<h2 id="the-scenario-thelook-fashion-search">The Scenario: TheLook Fashion Search </h2>
<p>Imagine a customer lands on your e-commerce site and types "something cute for a beach vacation." With traditional keyword search, they get zero results—no product in your catalog contains those exact words. Frustrated, they leave.</p>
<p>Now imagine a different experience. The same query returns sundresses, swimwear cover-ups, and flowy shorts—products that perfectly match what the customer had in mind, even though none contain the word "beach" in their titles. That's the experience vector search enables.</p>
<p>To demonstrate how Vector Search 2.0 makes this possible, we'll build a product search system using <a href="https://console.cloud.google.com/marketplace/product/bigquery-public-data/thelook-ecommerce">TheLook</a>, a realistic e-commerce dataset with 30,000 fashion items across 26 categories. Each product has attributes you'd find in any real catalog:</p>
<p><img src="assets/thelook_scenario.png" alt="TheLook Scenario"></p>
<h3 id="the-search-challenges-well-solve">The Search Challenges We'll Solve </h3>
<p>Real customers don't search the way databases expect. They search the way they think:</p>
<p><img src="assets/search_challenges_table.png" alt="Search Challenges"></p>
<p>Vector Search 2.0 solves all four challenges with a unified architecture. The rest of this post walks through the <a href="https://github.com/GoogleCloudPlatform/generative-ai/blob/main/embeddings/vector-search-2-intro.ipynb">official tutorial notebook</a>, showing how each piece fits together.</p>
<h2 id="vector-search-20-data-architecture">Vector Search 2.0 Data Architecture </h2>
<p>Before diving into code, let's understand how Vector Search 2.0 organizes your data. The architecture centers on three key concepts: Collections, Data Objects, and Indexes.</p>
<p><img src="assets/vs20_data_arch.jpeg" alt="Data Architecture"></p>
<p>A <strong>Collection</strong> defines your data structure—the fields you want to store and which ones should be embedded. <strong>Data Objects</strong> are the actual items (products, documents, images) stored in a Collection, each with its data and auto-generated vectors or your own vectors. An <strong>Index</strong> optimizes queries at scale, enabling millisec latency across billions of items. You can start without an index for development with zero setup time, then add one when you need production performance.</p>
<h2 id="building-thelook-search-step-by-step">Building TheLook Search: Step by Step </h2>
<p>Now let's build a working product search system. We'll load 10,000 fashion items from TheLook, enable auto-embeddings, and run semantic, keyword, and hybrid searches—all in about 50 lines of code.</p>
<h3 id="step-1-create-a-collection-with-auto-embeddings">Step 1: Create a Collection with Auto-Embeddings </h3>
<p>A Collection is like a database table with superpowers. You define your data schema and tell Vector Search 2.0 which fields should be embedded:</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-from">from</span> google<span class="token punctuation">.</span>cloud <span class="token keyword keyword-import">import</span> vectorsearch_v1beta

client <span class="token operator">=</span> vectorsearch_v1beta<span class="token punctuation">.</span>VectorSearchServiceClient<span class="token punctuation">(</span><span class="token punctuation">)</span>

request <span class="token operator">=</span> vectorsearch_v1beta<span class="token punctuation">.</span>CreateCollectionRequest<span class="token punctuation">(</span>
    parent<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"projects/</span><span class="token interpolation"><span class="token punctuation">{</span>PROJECT_ID<span class="token punctuation">}</span></span><span class="token string">/locations/</span><span class="token interpolation"><span class="token punctuation">{</span>LOCATION<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">,</span>
    collection_id<span class="token operator">=</span><span class="token string">"thelook_products"</span><span class="token punctuation">,</span>
    collection<span class="token operator">=</span><span class="token punctuation">{</span>
        <span class="token string">"data_schema"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
            <span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"object"</span><span class="token punctuation">,</span>
            <span class="token string">"properties"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
                <span class="token string">"id"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"string"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                <span class="token string">"name"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"string"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                <span class="token string">"category"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"string"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                <span class="token string">"retail_price"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"number"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token string">"vector_schema"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
            <span class="token string">"name_dense_embedding"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
                <span class="token string">"dense_vector"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
                    <span class="token string">"dimensions"</span><span class="token punctuation">:</span> <span class="token number">768</span><span class="token punctuation">,</span>
                    <span class="token string">"vertex_embedding_config"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
                        <span class="token string">"model_id"</span><span class="token punctuation">:</span> <span class="token string">"gemini-embedding-001"</span><span class="token punctuation">,</span>
                        <span class="token string">"text_template"</span><span class="token punctuation">:</span> <span class="token string">"{name}"</span><span class="token punctuation">,</span>
                        <span class="token string">"task_type"</span><span class="token punctuation">:</span> <span class="token string">"RETRIEVAL_DOCUMENT"</span><span class="token punctuation">,</span>
                    <span class="token punctuation">}</span><span class="token punctuation">,</span>
                <span class="token punctuation">}</span><span class="token punctuation">,</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

collection <span class="token operator">=</span> client<span class="token punctuation">.</span>create_collection<span class="token punctuation">(</span>request<span class="token operator">=</span>request<span class="token punctuation">)</span>
</code></pre><p>This code defines a Collection with two schemas: <code>data_schema</code> specifies the product fields (id, name, category, price), and <code>vector_schema</code> defines how embeddings are generated. The <code>vertex_embedding_config</code> is the key. It tells the system: "Take the product <code>name</code>, send it to <a href="https://docs.cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings#supported-models">gemini-embedding-001</a>, and store the resulting 768-dimensional vector." You never call an embedding API yourself.</p>
<h3 id="step-2-load-products-as-data-objects">Step 2: Load Products as Data Objects </h3>
<p>With the Collection ready, load your product catalog using batch operations. Each product becomes a Data Object with its data fields populated and the <code>vectors</code> field left empty—Vector Search 2.0 automatically generates the embeddings:</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>data_client <span class="token operator">=</span> vectorsearch_v1beta<span class="token punctuation">.</span>DataObjectServiceClient<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Load products in batches</span>
<span class="token keyword keyword-for">for</span> batch <span class="token keyword keyword-in">in</span> product_batches<span class="token punctuation">:</span>
    batch_request <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token punctuation">{</span>
            <span class="token string">"data_object_id"</span><span class="token punctuation">:</span> product<span class="token punctuation">[</span><span class="token string">"id"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token string">"data_object"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
                <span class="token string">"data"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
                    <span class="token string">"id"</span><span class="token punctuation">:</span> product<span class="token punctuation">[</span><span class="token string">"id"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token string">"name"</span><span class="token punctuation">:</span> product<span class="token punctuation">[</span><span class="token string">"name"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token string">"category"</span><span class="token punctuation">:</span> product<span class="token punctuation">[</span><span class="token string">"category"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token string">"retail_price"</span><span class="token punctuation">:</span> product<span class="token punctuation">[</span><span class="token string">"retail_price"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">}</span><span class="token punctuation">,</span>
                <span class="token string">"vectors"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span>  <span class="token comment"># Auto-generated from name field</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span>
        <span class="token keyword keyword-for">for</span> product <span class="token keyword keyword-in">in</span> batch
    <span class="token punctuation">]</span>

    request <span class="token operator">=</span> vectorsearch_v1beta<span class="token punctuation">.</span>BatchCreateDataObjectsRequest<span class="token punctuation">(</span>
        parent<span class="token operator">=</span>collection<span class="token punctuation">.</span>name<span class="token punctuation">,</span>
        requests<span class="token operator">=</span>batch_request<span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    data_client<span class="token punctuation">.</span>batch_create_data_objects<span class="token punctuation">(</span>request<span class="token operator">=</span>request<span class="token punctuation">)</span>
</code></pre><p>Notice that <code>vectors</code> is an empty object. This is where auto-embeddings work their magic. Here's what happens behind the scenes when you create a Data Object:</p>
<p><img src="assets/autoemb_gen.png" alt="Auto-embedding generations"></p>
<p>You send the product data with empty vectors. Vector Search 2.0 calls the embedding model, gets the vector, and stores everything together. The same auto-embedding process runs whenever you update an existing Data Object, keeping your vectors in sync with your data.</p>
<h3 id="step-3-search-with-hybrid-search">Step 3: Search with Hybrid Search </h3>
<p>Now the payoff. Vector Search 2.0 supports three search modes: <strong>semantic search</strong> (understands intent via embeddings), <strong>text search</strong> (keyword matching), and <strong>hybrid search</strong> (combines both). Hybrid search delivers the best results for most use cases—semantic search finds "Board Shorts" when users search "men's outfit for beach," while text search ensures exact matches like product codes aren't missed.</p>
<p><img src="assets/hybrid_search.png" alt="Hybrid Search"></p>
<p>Here's hybrid search in action for "men's short for beach":</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>query_text <span class="token operator">=</span> <span class="token string">"men's short for beach"</span>

batch_request <span class="token operator">=</span> vectorsearch_v1beta<span class="token punctuation">.</span>BatchSearchDataObjectsRequest<span class="token punctuation">(</span>
    parent<span class="token operator">=</span>collection<span class="token punctuation">.</span>name<span class="token punctuation">,</span>
    searches<span class="token operator">=</span><span class="token punctuation">[</span>
        vectorsearch_v1beta<span class="token punctuation">.</span>Search<span class="token punctuation">(</span>
            semantic_search<span class="token operator">=</span>vectorsearch_v1beta<span class="token punctuation">.</span>SemanticSearch<span class="token punctuation">(</span>
                search_text<span class="token operator">=</span>query_text<span class="token punctuation">,</span>
                search_field<span class="token operator">=</span><span class="token string">"name_dense_embedding"</span><span class="token punctuation">,</span>
                task_type<span class="token operator">=</span><span class="token string">"QUESTION_ANSWERING"</span><span class="token punctuation">,</span>
                top_k<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span>
                output_fields<span class="token operator">=</span>vectorsearch_v1beta<span class="token punctuation">.</span>OutputFields<span class="token punctuation">(</span>
                    data_fields<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"name"</span><span class="token punctuation">,</span> <span class="token string">"category"</span><span class="token punctuation">,</span> <span class="token string">"retail_price"</span><span class="token punctuation">]</span>
                <span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span>
        <span class="token punctuation">)</span><span class="token punctuation">,</span>
        vectorsearch_v1beta<span class="token punctuation">.</span>Search<span class="token punctuation">(</span>
            text_search<span class="token operator">=</span>vectorsearch_v1beta<span class="token punctuation">.</span>TextSearch<span class="token punctuation">(</span>
                search_text<span class="token operator">=</span>query_text<span class="token punctuation">,</span>
                data_field_names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"name"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                top_k<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span>
                output_fields<span class="token operator">=</span>vectorsearch_v1beta<span class="token punctuation">.</span>OutputFields<span class="token punctuation">(</span>
                    data_fields<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"name"</span><span class="token punctuation">,</span> <span class="token string">"category"</span><span class="token punctuation">,</span> <span class="token string">"retail_price"</span><span class="token punctuation">]</span>
                <span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span>
        <span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span><span class="token punctuation">,</span>
    combine<span class="token operator">=</span>vectorsearch_v1beta<span class="token punctuation">.</span>BatchSearchDataObjectsRequest<span class="token punctuation">.</span>CombineResultsOptions<span class="token punctuation">(</span>
        ranker<span class="token operator">=</span>vectorsearch_v1beta<span class="token punctuation">.</span>Ranker<span class="token punctuation">(</span>
            rrf<span class="token operator">=</span>vectorsearch_v1beta<span class="token punctuation">.</span>ReciprocalRankFusion<span class="token punctuation">(</span>weights<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

results <span class="token operator">=</span> search_client<span class="token punctuation">.</span>batch_search_data_objects<span class="token punctuation">(</span>request<span class="token operator">=</span>batch_request<span class="token punctuation">)</span>
</code></pre><p>This code runs two searches in parallel: a <code>semantic_search</code> that understands the query's intent through embeddings, and a <code>text_search</code> that finds keyword matches in product names. The <code>combine</code> parameter with <code>ReciprocalRankFusion</code> merges both result sets into a single ranked list.</p>
<p>Reciprocal Rank Fusion (RRF) combines the rankings from both searches. Products that score well on both semantic relevance and keyword matching rise to the top. Here are the actual results from running this query on TheLook:</p>
<pre data-role="codeBlock" data-info="" class="language-text"><code>Hybrid search results for 'Men's short for beach' (Semantic + Text with built-in RRF):
================================================================================
 1. Mens Racing Beach Fitted Short Trunk Jammer - $20.97
 2. Beach Depot UPF 50+ Men's Short Sleeve Rash Guard Shirt - $29.95
 3. Relaxed Boardshort Short - $51.75
 4. Original Penguin Men's Fashion Short - $79.00
 5. Bottoms Out Men's Ocean Print Swim Short - $25.00
 6. GOTS Certified 100% Organic Cotton Shorts for Men - $22.00
 7. Men's Jersey Short - $8.49
 8. Hurley Men's 4D Boardshort - $149.50
 9. Mens Hawaiian Board Shorts Island Khaki - $24.99
10. Micros Men's Way Short - $40.88
</code></pre><h4 id="why-task-type-embeddings-matter">Why Task Type Embeddings Matter </h4>
<p>Notice the <code>task_type</code> parameters in the code above: <code>RETRIEVAL_DOCUMENT</code> when indexing products, and <code>QUESTION_ANSWERING</code> when searching. This isn't arbitrary—it's a key technique for improving search quality by letting the embedding model work <strong>like a recommendation model</strong>.</p>
<p>Most vector search use cases rely on simple similarity matching, but this often fails to provide production-level search quality because questions and answers aren't inherently similar in embedding space. "What's good for a beach vacation?" and "Board Shorts" have different semantics, yet they should match. Task type embeddings solve this by optimizing the embedding model for asymmetric relationships: documents are embedded differently than queries, creating an embedding space where relevant matches cluster together—adding the capability of recommendation, finding relevant items based on user intent.</p>
<p><img src="assets/task_types.png" alt="Task Type Embeddings"></p>
<p>Using task-specific embeddings can improve search quality by 30-40% compared to generic embeddings. For a deep dive into how this works, see the <a href="https://github.com/GoogleCloudPlatform/generative-ai/blob/main/embeddings/task-type-embedding.ipynb">Task Type Embedding notebook</a>.</p>
<h3 id="step-4-add-filters-for-business-logic">Step 4: Add Filters for Business Logic </h3>
<p>Beyond vector search, you can query your data using SQL-like filters—useful for browsing by category, filtering by price range, or any business logic that doesn't require semantic understanding. Here's how to find affordable jeans under $75:</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>request <span class="token operator">=</span> vectorsearch_v1beta<span class="token punctuation">.</span>QueryDataObjectsRequest<span class="token punctuation">(</span>
    parent<span class="token operator">=</span>collection<span class="token punctuation">.</span>name<span class="token punctuation">,</span>
    <span class="token builtin">filter</span><span class="token operator">=</span><span class="token punctuation">{</span>
        <span class="token string">"$and"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
            <span class="token punctuation">{</span><span class="token string">"category"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">"$eq"</span><span class="token punctuation">:</span> <span class="token string">"Jeans"</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
            <span class="token punctuation">{</span><span class="token string">"retail_price"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">"$lt"</span><span class="token punctuation">:</span> <span class="token number">75</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">]</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    output_fields<span class="token operator">=</span>vectorsearch_v1beta<span class="token punctuation">.</span>OutputFields<span class="token punctuation">(</span>data_fields<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"*"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

results <span class="token operator">=</span> search_client<span class="token punctuation">.</span>query_data_objects<span class="token punctuation">(</span>request<span class="token operator">=</span>request<span class="token punctuation">)</span>
</code></pre><p>The <a href="https://docs.cloud.google.com/vertex-ai/docs/vector-search-2/query-search/query#filter_expression_language">filter expression language</a> supports comparison operators (<code>$eq</code>, <code>$ne</code>, <code>$gt</code>, <code>$gte</code>, <code>$lt</code>, <code>$lte</code>), logical operators (<code>$and</code>, <code>$or</code>), and array operators (<code>$in</code>, <code>$nin</code>, <code>$all</code>). Here's what the query returns:</p>
<pre data-role="codeBlock" data-info="" class="language-text"><code>Jeans under $75:
"Levi's 512 Misses Perfectly Slimming Boo... ($54.00)", 
'YMI Juniors Fleur De Lis Capri Jean... ($25.00)', 
"Lucky Brand Jeans Men's Style: Slim Boot... ($73.96)", 
"Hurley Men's 84 Slim Denim Pant... ($69.45)", 
"KR3W Klassic Jeans - Dark Blue... ($64.00)"
</code></pre><p>You can also combine filters with semantic or hybrid search—for example, finding "casual summer wear" but only in the Shorts category under $50.</p>
<h3 id="step-5-from-zero-to-billion-scale">Step 5: From Zero to Billion Scale </h3>
<p>Everything we've done so far uses <strong>kNN (k-Nearest Neighbors)</strong>—a brute-force algorithm that compares your query against every vector in the Collection. kNN is perfect for development: zero setup time, instant searches, and 100% accuracy. But as your dataset grows, latency increases linearly.</p>
<p>For production at scale, Vector Search 2.0 offers <strong>ANN (Approximate Nearest Neighbor)</strong> indexes powered by Google's <a href="https://github.com/google-research/google-research/tree/master/scann">ScaNN (Scalable Nearest Neighbors)</a> algorithm—the same technology behind Google Search, YouTube, and Google Play. ANN trades a tiny amount of accuracy (~99%) for massive speed gains: sub-10ms latency even with billions of vectors.</p>
<p><img src="assets/ann.jpeg" alt="ANN"></p>
<p>Creating an ANN index is straightforward:</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>request <span class="token operator">=</span> vectorsearch_v1beta<span class="token punctuation">.</span>CreateIndexRequest<span class="token punctuation">(</span>
    parent<span class="token operator">=</span>collection<span class="token punctuation">.</span>name<span class="token punctuation">,</span>
    index_id<span class="token operator">=</span><span class="token string">"product-search-index"</span><span class="token punctuation">,</span>
    index<span class="token operator">=</span><span class="token punctuation">{</span>
        <span class="token string">"index_field"</span><span class="token punctuation">:</span> <span class="token string">"name_dense_embedding"</span><span class="token punctuation">,</span>
        <span class="token string">"filter_fields"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"category"</span><span class="token punctuation">,</span> <span class="token string">"retail_price"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token string">"store_fields"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"name"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

operation <span class="token operator">=</span> client<span class="token punctuation">.</span>create_index<span class="token punctuation">(</span>request<span class="token operator">=</span>request<span class="token punctuation">)</span>
index <span class="token operator">=</span> operation<span class="token punctuation">.</span>result<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><p>The <code>index_field</code> specifies which vector field to index, <code>filter_fields</code> enables filtering during search, and <code>store_fields</code> caches frequently accessed data in the index for faster retrieval. Once created, the index accelerates searches automatically—no code changes required.</p>
<h2 id="the-complete-picture">The Complete Picture </h2>
<p>In just five steps—with steps 1 through 4 taking only about <strong>5 minutes</strong>—we built a production-ready product search system:</p>
<p><img src="assets/complete_picture.jpeg" alt="Complete Picture"></p>
<p>Vector Search 2.0 eliminates the infrastructure complexity that typically slows down vector search adoption. You focus on your product; the platform handles embeddings, indexing, and scaling.</p>
<h3 id="try-it-yourself">Try It Yourself </h3>
<p>Ready to build your own vector search? Start here:</p>
<p><strong>Quick start:</strong> <a href="https://github.com/GoogleCloudPlatform/generative-ai/blob/main/embeddings/vector-search-2-intro.ipynb">Vector Search 2.0 Introduction Notebook</a> — Run in Colab with one click. Load TheLook, run every search type, and see results in minutes.</p>
<p><strong>Learn more:</strong></p>
<ul>
<li><a href="https://cloud.google.com/vertex-ai/docs/vector-search-2/overview">Vector Search 2.0 Documentation</a></li>
<li><a href="https://cloud.google.com/python/docs/reference/vectorsearch/latest">Python SDK Reference</a></li>
</ul>
<hr>
<p>Vector search used to require stitching together embedding pipelines, feature stores, ANN indexes, and full-text search engines. Vector Search 2.0 replaces that complexity with a single, fully managed service—so you can go from zero to billion-scale semantic search without becoming an infrastructure expert.</p>
<p>The gap between "I've heard of vector search" and "I'm running it in production" just got a lot smaller.</p>

      </div>
      
      
    
    
    
    
    
    
  
    </body></html>